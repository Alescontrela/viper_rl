seed: 1234

batch_size: 64
lr: 1.e-4
total_steps: 800000
warmup_steps: 0
save_interval: 10000
test_interval: 10000
viz_interval: 10000
log_interval: 100
data_path: "viper_rl_data/datasets/dmc"

ema: 0.9999
optimizer: "adam"
lr_schedule: "constant"

image_size: 64
seq_len: 16
frame_skip: 1
ae_ckpt: "viper_rl_data/checkpoints/dmc_vqgan"

n_classes: 16
class_cond: true

model: "videogpt"
transformer:
  embed_dim: 256
  num_heads: 8
  num_layers: 8
  mlp_dim: 1024
  dropout: 0.1
  attention_dropout: 0.1

open_loop_ctx: 1
